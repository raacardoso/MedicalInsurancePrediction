{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zPd29AmTFSV"
   },
   "source": [
    "# **Problema**\n",
    "\n",
    "* Você é um profissional encarregado de desenvolver um modelo preditivo de regressão para prever o valor dos custos médicos individuais cobrados pelo seguro de saúde.\n",
    "\n",
    "* A base de dados exemplos está anexada como exemplo.csv.\n",
    "\n",
    "* Você precisa alimentar ela com mais informações ou utilizar uma outra de sua preferência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOt6ssPKS7ef"
   },
   "source": [
    "# **Tarefas**\n",
    "\n",
    "Exploração de dados:\n",
    "\n",
    "  * Carregue a base de dados e explore suas características.\n",
    "  * Analise estatísticas descritivas e visualize distribuições relevantes.\n",
    "       \n",
    "Pré-processamento de dados:\n",
    "      \n",
    "  * Realize a limpeza dos dados, tratando valores ausentes (se necessário).\n",
    "  * Converta variáveis categóricas em formatos adequados para modelagem.\n",
    "\n",
    "Modelagem:\n",
    "    \n",
    "  * Crie um modelo preditivo de regressão utilizando uma técnica à sua escolha (por exemplo, Regressão Linear, Árvores de Decisão, etc).      \n",
    "  * Divida o conjunto de dados em conjuntos de treinamento e teste.\n",
    "\n",
    "Treinamento e avaliação do modelo:\n",
    "\n",
    "  * Treine o modelo com o conjunto de treinamento.\n",
    "         \n",
    "Validação estatística:\n",
    "  * Utilize métricas estatísticas para validar a eficácia do modelo (p-value, intervalos de confiança).\n",
    "\n",
    "\n",
    "**O que avaliaremos:**\n",
    "\n",
    "  * Apresente resultados visuais, como gráficos de previsões vs. valores reais.\n",
    "  * Elabore um relatório que inclua uma análise dos resultados, insights obtidos e validação estatística.\n",
    "  \n",
    "**Observações:**\n",
    "\n",
    "  * Esperamos que o modelo seja capaz de fazer previsões confiáveis dos custos médicos individuais com base nas características fornecidas.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problema**\n",
    "\n",
    "* Você é um profissional encarregado de desenvolver um modelo preditivo de regressão para prever o valor dos custos médicos individuais cobrados pelo seguro de saúde.\n",
    "\n",
    "* A base de dados exemplos está anexada como exemplo.csv.\n",
    "\n",
    "* Você precisa alimentar ela com mais informações ou utilizar uma outra de sua preferência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tarefas**\n",
    "\n",
    "Exploração de dados:\n",
    "\n",
    "  * Carregue a base de dados e explore suas características.\n",
    "  * Analise estatísticas descritivas e visualize distribuições relevantes.\n",
    "       \n",
    "Pré-processamento de dados:\n",
    "      \n",
    "  * Realize a limpeza dos dados, tratando valores ausentes (se necessário).\n",
    "  * Converta variáveis categóricas em formatos adequados para modelagem.\n",
    "\n",
    "Modelagem:\n",
    "    \n",
    "  * Crie um modelo preditivo de regressão utilizando uma técnica à sua escolha (por exemplo, Regressão Linear, Árvores de Decisão, etc).      \n",
    "  * Divida o conjunto de dados em conjuntos de treinamento e teste.\n",
    "\n",
    "Treinamento e avaliação do modelo:\n",
    "\n",
    "  * Treine o modelo com o conjunto de treinamento.\n",
    "         \n",
    "Validação estatística:\n",
    "  * Utilize métricas estatísticas para validar a eficácia do modelo (p-value, intervalos de confiança).\n",
    "\n",
    "\n",
    "**O que avaliaremos:**\n",
    "\n",
    "  * Apresente resultados visuais, como gráficos de previsões vs. valores reais.\n",
    "  * Elabore um relatório que inclua uma análise dos resultados, insights obtidos e validação estatística.\n",
    "  \n",
    "**Observações:**\n",
    "\n",
    "  * Esperamos que o modelo seja capaz de fazer previsões confiáveis dos custos médicos individuais com base nas características fornecidas.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrega**\n",
    "\n",
    " * Como entregável, o grupo deve enviar um vídeo junto com o link do github do projeto e o código desenvolvido, apresentando o passo a passo do que foi utilizado como a fonte de dados e como os modelos foram criados.\n",
    "  \n",
    " * O vídeo deve estar em uma plataforma como Youtube.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Solução**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"medical_insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "sns.histplot(data=dataset, x='idade', kde=True, bins=30, color='blue', ax=axs[0, 0])\n",
    "sns.histplot(data=dataset, x='imc', kde=True, bins=30, color='orange', ax=axs[0, 1])\n",
    "sns.histplot(data=dataset, x='filhos', kde=True, bins=30, color='green', ax=axs[1, 0])\n",
    "sns.histplot(data=dataset, x='encargos', kde=True, bins=30, color='red', ax=axs[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, col in enumerate(['genero', 'fumante', 'regiao']):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    x = dataset[col].value_counts().reset_index()\n",
    "    plt.title(col)\n",
    "    # Use autopct para formatar a porcentagem e incluir a descrição\n",
    "    plt.pie(x=x['count'], labels=x[col], autopct=lambda p : '{:.1f}%'.format(p))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dataset = dataset.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "correlation_dataset.genero = label_encoder.fit_transform(correlation_dataset.genero)\n",
    "correlation_dataset.fumante = label_encoder.fit_transform(correlation_dataset.fumante)\n",
    "correlation_dataset.regiao = label_encoder.fit_transform(correlation_dataset.regiao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation_dataset.corr(method = 'pearson'), annot=True, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue=\"genero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dataset,x=dataset.encargos,y=dataset.fumante,hue=dataset.idade)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='encargos', data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset[np.abs(stats.zscore(dataset.encargos)) < 3]\n",
    "#A escolha de 3 como limiar está baseada na Regra Empírica (ou Regra dos 68-95-99.7), que diz que:\n",
    "\n",
    "#Aproximadamente 68% dos dados em uma distribuição normal estão dentro de 1 desvio padrão da média.\n",
    "#Aproximadamente 95% estão dentro de 2 desvios padrão.\n",
    "#Aproximadamente 99.7% estão dentro de 3 desvios padrão.\n",
    "#Um z-score de 3, vamos excluir apenas os valores mais extremos, que são menos de 0.3% dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='encargos', data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Encargos Médios por Região com Intervalos de Confiança\" refere-se a uma análise que mostra a média dos custos ou despesas médicas (ou \"encargos\") para cada região geográfica, acompanhada de um intervalo de confiança que indica a variabilidade ou incerteza dessa média.\n",
    "\n",
    "Um intervalo de confiança fornece uma faixa em torno da média que, com um certo nível de confiança (geralmente 95%), contém o valor real da média para toda a população. Ele reflete a incerteza em torno da estimativa da média.\n",
    "Um intervalo de confiança mais amplo indica mais incerteza (mais variação nos dados), enquanto um intervalo mais estreito indica mais precisão (menos variação nos dados).\n",
    "Visualização Gráfica:\n",
    "No gráfico, as barras representam os encargos médios por região, e as \"linhas\" ou \"barras de erro\" que saem das barras principais indicam o intervalo de confiança. Se as barras de erro forem curtas, a média é estimada com maior precisão; se forem longas, há mais incerteza.\n",
    "\n",
    "\n",
    "Essa visualização é útil para comparar as médias entre regiões e entender a confiança que podemos ter em cada estimativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o tamanho da figura\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Subgráfico 1: Média de encargos por gênero\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(data=dataset, x='genero', y='encargos', estimator=np.mean, hue='genero', palette='muted', legend=False)\n",
    "plt.title('Média de Encargos por Gênero')\n",
    "plt.xlabel('Gênero')\n",
    "plt.ylabel('Média de Encargos')\n",
    "\n",
    "# Adicionando rótulos no topo das barras\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{p.get_height():.2f}', \n",
    "                       (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                       ha='center', va='center', \n",
    "                       xytext=(0, 9), \n",
    "                       textcoords='offset points')\n",
    "\n",
    "# Subgráfico 2: Média de encargos por região\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(data=dataset, x='regiao', y='encargos', estimator=np.mean, hue='regiao', palette='muted', legend=False)\n",
    "plt.title('Média de Encargos por Região')\n",
    "plt.xlabel('Região')\n",
    "plt.ylabel('Média de Encargos')\n",
    "\n",
    "# Adicionando rótulos no topo das barras\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f'{p.get_height():.2f}', \n",
    "                       (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                       ha='center', va='center', \n",
    "                       xytext=(0, 9), \n",
    "                       textcoords='offset points')\n",
    "\n",
    "# Ajustando o layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(dataset[['genero','regiao','fumante']],dtype=int)\n",
    "dataset = pd.concat([dataset[['idade','imc','filhos','encargos']],dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['encargos'], axis=1)\n",
    "y = dataset['encargos']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(labels, predictions):\n",
    "    errors = np.abs(labels - predictions)\n",
    "    relative_errors = errors / np.abs(labels)\n",
    "    mape = np.mean(relative_errors) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    abs = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape_result = calculate_mape(y_test, y_pred)\n",
    "\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {abs}')\n",
    "    print(f'R-squared: {r2}')\n",
    "    print(f\"O MAPE é: {mape_result:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(model, X_train, X_test, y_train, y_test):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f'O score de treino é: {train_score}')\n",
    "    print(f'O score de test é: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X_train, x_axis, y_train, y_axis):\n",
    "  kfold  = KFold(n_splits=10, shuffle=True) \n",
    "\n",
    "  x = x_axis\n",
    "  y = y_axis\n",
    "\n",
    "  linear = LinearRegression()\n",
    "  linear.fit(X_train, y_train)\n",
    "\n",
    "  knn = KNeighborsRegressor(n_neighbors=8, metric= 'euclidean', weights='distance') \n",
    "  knn.fit(X_train, y_train) \n",
    "\n",
    "  svm = SVR()\n",
    "  svm.fit(X_train, y_train)\n",
    "\n",
    "  rf = RandomForestRegressor(random_state=7) \n",
    "  rf.fit(X_train, y_train)\n",
    "\n",
    "  linear_result = cross_val_score(linear, x, y, cv=kfold)\n",
    "  knn_result = cross_val_score(knn, x, y, cv=kfold)\n",
    "  svm_result = cross_val_score(svm, x, y, cv=kfold)\n",
    "  rf_result = cross_val_score(rf, x, y, cv=kfold)\n",
    "\n",
    "  dic_models = {\n",
    "    \"LINEAR\": linear_result.mean(),\n",
    "    \"KNN\": knn_result.mean(),\n",
    "    \"SVM\": svm_result.mean(),\n",
    "    \"Random Forest\": rf_result.mean()\n",
    "  }\n",
    "  # Select the best model.\n",
    "  best_model = max(dic_models, key=dic_models.get)\n",
    "\n",
    "  print(\"LINEAR (R^2): {0}\\nKNN (R^2): {1}\\nSVM (R^2): {2}\\nRandom Forest (R^2): {3}\".format(linear_result.mean(), knn_result.mean(), svm_result.mean(), rf_result.mean()))\n",
    "  print(\"O melhor modelo é o {0} com valor: {1}\".format(best_model, dic_models[best_model]))\n",
    "  \n",
    "cross_validation(X_train, X, y_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "    'n_estimators': [10, 30 , 40, 100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'min_samples_split': [2, 5, 10],            \n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf,\n",
    "    param_distributions = random_grid,\n",
    "    n_iter = 100,\n",
    "    cv = 3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs = -1\n",
    ")# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators= 800,\n",
    "    min_samples_split= 2,\n",
    "    min_samples_leaf= 1,\n",
    "    max_features= 'sqrt',\n",
    "    max_depth= 90,\n",
    "    bootstrap= False,\n",
    "    random_state=42\n",
    ")\n",
    "forest_model.fit(X_train, y_train)\n",
    "y_pred = forest_model.predict(X_test)\n",
    "\n",
    "generate_metrics(y_test, y_pred)\n",
    "calculate_score(forest_model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_graphic(y_test, y_pred):\n",
    "    # Plotar Grafico\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.scatter(y_test, y_test, color='green', label='Encargos Reais')\n",
    "    plt.scatter(y_test, y_pred, color='red', label='Previsão de Encargos')\n",
    "    plt.title('Previsão de Encargos vs Encargos Reais')\n",
    "    plt.xlabel('Encargos Reais')\n",
    "    plt.ylabel('Previsão de Encargos')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "plot_score_graphic(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CA_OUbqTf7m"
   },
   "source": [
    "# **Entrega**\n",
    "\n",
    " * Como entregável, o grupo deve enviar um vídeo junto com o link do github do projeto e o código desenvolvido, apresentando o passo a passo do que foi utilizado como a fonte de dados e como os modelos foram criados.\n",
    "  \n",
    " * O vídeo deve estar em uma plataforma como Youtube.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm9Hxcmls7pB"
   },
   "source": [
    "# **Solução**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"medical_insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,28))\n",
    "for i, col in enumerate( ['idade','imc','filhos','encargos']):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.histplot(data = dataset,\n",
    "            x = col,\n",
    "            kde = True,\n",
    "            bins = 30,\n",
    "            color = 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "for i,col in enumerate(['genero','fumante','regiao']):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    x=dataset[col].value_counts().reset_index()\n",
    "    plt.title(col)\n",
    "    plt.pie(x=x['count'],labels=x[col],autopct=\"%0.1f%%\",colors=sns.color_palette('muted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dataset = dataset.copy()\n",
    "label_encoder = LabelEncoder()\n",
    "correlation_dataset.genero = label_encoder.fit_transform(correlation_dataset.genero)\n",
    "correlation_dataset.fumante = label_encoder.fit_transform(correlation_dataset.fumante)\n",
    "correlation_dataset.regiao = label_encoder.fit_transform(correlation_dataset.regiao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation_dataset.corr(method = 'pearson'), annot=True, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue=\"genero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dataset,x=dataset.encargos,y=dataset.fumante,hue=dataset.idade)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='encargos', data=dataset, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset[np.abs(stats.zscore(dataset.encargos)) < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='encargos', data=dataset, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=dataset,x=dataset.genero,y=dataset.encargos,estimator=np.mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=dataset,x=dataset.regiao,y=dataset.encargos,estimator=np.mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(dataset[['genero','regiao','fumante']],dtype=int)\n",
    "dataset = pd.concat([dataset[['idade','imc','filhos','encargos']],dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['encargos'], axis=1)\n",
    "y = dataset['encargos']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(labels, predictions):\n",
    "    errors = np.abs(labels - predictions)\n",
    "    relative_errors = errors / np.abs(labels)\n",
    "    mape = np.mean(relative_errors) * 100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metrics(y_test, y_pred):\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    abs = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape_result = calculate_mape(y_test, y_pred)\n",
    "\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {abs}')\n",
    "    print(f'R-squared: {r2}')\n",
    "    print(f\"O MAPE é: {mape_result:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_graphic(y_test, y_pred):\n",
    "    # Plotar Grafico\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.scatter(y_test, y_test, color='green', label='Encargos Reais')\n",
    "    plt.scatter(y_test, y_pred, color='red', label='Previsão de Encargos')\n",
    "    plt.title('Previsão de Encargos vs Encargos Reais')\n",
    "    plt.xlabel('Encargos Reais')\n",
    "    plt.ylabel('Previsão de Encargos')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(model, X_train, X_test, y_train, y_test):\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f'O score de treino é: {train_score}')\n",
    "    print(f'O score de test é: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X_train, x_axis, y_train, y_axis):\n",
    "  kfold  = KFold(n_splits=10, shuffle=True) \n",
    "\n",
    "  x = x_axis\n",
    "  y = y_axis\n",
    "\n",
    "  linear = LinearRegression()\n",
    "  linear.fit(X_train, y_train)\n",
    "\n",
    "  knn = KNeighborsRegressor(n_neighbors=8, metric= 'euclidean', weights='distance') \n",
    "  knn.fit(X_train, y_train) \n",
    "\n",
    "  svm = SVR()\n",
    "  svm.fit(X_train, y_train)\n",
    "\n",
    "  rf = RandomForestRegressor(random_state=7) \n",
    "  rf.fit(X_train, y_train)\n",
    "\n",
    "  linear_result = cross_val_score(linear, x, y, cv=kfold)\n",
    "  knn_result = cross_val_score(knn, x, y, cv=kfold)\n",
    "  svm_result = cross_val_score(svm, x, y, cv=kfold)\n",
    "  rf_result = cross_val_score(rf, x, y, cv=kfold)\n",
    "\n",
    "  dic_models = {\n",
    "    \"LINEAR\": linear_result.mean(),\n",
    "    \"KNN\": knn_result.mean(),\n",
    "    \"SVM\": svm_result.mean(),\n",
    "    \"RF\": rf_result.mean()\n",
    "  }\n",
    "  # Select the best model.\n",
    "  best_model = max(dic_models, key=dic_models.get)\n",
    "\n",
    "  print(\"LINEAR (R^2): {0}\\nKNN (R^2): {1}\\nSVM (R^2): {2}\\nRandom Forest (R^2): {3}\".format(linear_result.mean(), knn_result.mean(), svm_result.mean(), rf_result.mean()))\n",
    "  print(\"O melhor modelo é : {0} com o valor: {1}\".format(best_model, dic_models[best_model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(X_train, X, y_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "    'n_estimators': [10, 30 , 40, 100, 150, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "    'min_samples_split': [2, 5, 10],            \n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf,\n",
    "    param_distributions = random_grid,\n",
    "    n_iter = 100,\n",
    "    cv = 3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs = -1\n",
    ")# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators= 800,\n",
    "    min_samples_split= 2,\n",
    "    min_samples_leaf= 1,\n",
    "    max_features= 'sqrt',\n",
    "    max_depth= 90,\n",
    "    bootstrap= False,\n",
    "    random_state=42\n",
    ")\n",
    "forest_model.fit(X_train, y_train)\n",
    "y_pred = forest_model.predict(X_test)\n",
    "\n",
    "generate_metrics(y_test, y_pred)\n",
    "calculate_score(forest_model, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_graphic(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
